"""
è®­ç»ƒæ¨¡å— - VAEè®­ç»ƒé€»è¾‘
"""
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from torchvision.utils import make_grid
import os
from datetime import datetime

from config import Config
from vae import create_vae_model, vae_loss_fn
from dataset import create_dataloader

class VAETrainer:
    """VAEè®­ç»ƒå™¨"""
    
    def __init__(self, model=None, dataloader=None):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: VAEæ¨¡å‹ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
            dataloader: æ•°æ®åŠ è½½å™¨ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
        """
        self.device = Config.device
        self.model = model if model is not None else create_vae_model()
        self.dataloader = dataloader if dataloader is not None else create_dataloader()
        
        if self.dataloader is None:
            raise ValueError("æ— æ³•åˆ›å»ºæ•°æ®åŠ è½½å™¨")
            
        # åˆ›å»ºä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(self.model.parameters(), lr=Config.learning_rate)
        
        # è®­ç»ƒç»Ÿè®¡
        self.train_losses = []
        self.recon_losses = []
        self.kl_losses = []
        
        print(f"ğŸš€ VAEè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"   æ•°æ®é›†å¤§å°: {len(self.dataloader.dataset)}")
        print(f"   æ‰¹æ¬¡æ•°é‡: {len(self.dataloader)}")
    
    def train_epoch(self, epoch):
        """
        è®­ç»ƒä¸€ä¸ªepoch
        
        Args:
            epoch: å½“å‰epochç¼–å·
            
        Returns:
            epoch_loss: å¹³å‡æŸå¤±
            epoch_recon_loss: å¹³å‡é‡å»ºæŸå¤±
            epoch_kl_loss: å¹³å‡KLæŸå¤±
        """
        self.model.train()
        total_loss = 0
        total_recon_loss = 0
        total_kl_loss = 0
        
        for batch_idx, (x, _) in enumerate(self.dataloader):
            x = x.to(self.device)
            
            # å‰å‘ä¼ æ’­
            x_hat, mu, logvar = self.model(x)
            
            # è®¡ç®—æŸå¤±
            loss, recon_loss, kl_loss = vae_loss_fn(x_hat, x, mu, logvar)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            total_recon_loss += recon_loss.item()
            total_kl_loss += kl_loss.item()
            
            # æ‰“å°è¿›åº¦
            if batch_idx % Config.print_interval == 0:
                print(f'  Epoch {epoch+1}/{Config.epochs}, '
                      f'Batch {batch_idx}/{len(self.dataloader)}, '
                      f'Loss: {loss.item():.2f}')
        
        # è®¡ç®—å¹³å‡æŸå¤±
        epoch_loss = total_loss / len(self.dataloader.dataset)
        epoch_recon_loss = total_recon_loss / len(self.dataloader.dataset)
        epoch_kl_loss = total_kl_loss / len(self.dataloader.dataset)
        
        return epoch_loss, epoch_recon_loss, epoch_kl_loss
    
    def save_samples(self, epoch, save_dir="results"):
        """
        ä¿å­˜ç”Ÿæˆæ ·æœ¬
        
        Args:
            epoch: å½“å‰epoch
            save_dir: ä¿å­˜ç›®å½•
        """
        os.makedirs(save_dir, exist_ok=True)
        
        self.model.eval()
        with torch.no_grad():
            # ç”Ÿæˆæ ·æœ¬
            samples = self.model.sample(Config.num_samples, self.device)
            
            # åå½’ä¸€åŒ–åˆ°[0,1]
            samples = (samples + 1) / 2
            samples = torch.clamp(samples, 0, 1)
            
            # åˆ›å»ºç½‘æ ¼
            grid = make_grid(samples, nrow=Config.grid_size, pad_value=1)
            
            # ä¿å­˜å›¾åƒ
            plt.figure(figsize=(8, 8))
            plt.imshow(grid.permute(1, 2, 0).cpu())
            plt.axis('off')
            plt.title(f'Generated Faces - Epoch {epoch+1}')
            
            filename = os.path.join(save_dir, f'generated_faces_epoch_{epoch+1}.png')
            plt.savefig(filename, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"  ğŸ’¾ æ ·æœ¬å·²ä¿å­˜: {filename}")
        
        self.model.train()
    
    def train(self):
        """å¼€å§‹è®­ç»ƒ"""
        print(f"ğŸ¯ å¼€å§‹è®­ç»ƒVAEæ¨¡å‹")
        print(f"   è®­ç»ƒè½®æ•°: {Config.epochs}")
        print(f"   å­¦ä¹ ç‡: {Config.learning_rate}")
        print(f"   æ‰¹æ¬¡å¤§å°: {Config.batch_size}")
        print("=" * 60)
        
        start_time = datetime.now()
        
        for epoch in range(Config.epochs):
            print(f"ğŸ“ˆ Epoch {epoch+1}/{Config.epochs}")
            
            # è®­ç»ƒä¸€ä¸ªepoch
            epoch_loss, recon_loss, kl_loss = self.train_epoch(epoch)
            
            # è®°å½•æŸå¤±
            self.train_losses.append(epoch_loss)
            self.recon_losses.append(recon_loss)
            self.kl_losses.append(kl_loss)
            
            # æ‰“å°ç»Ÿè®¡
            print(f"  âœ… Epoch {epoch+1} å®Œæˆ")
            print(f"     æ€»æŸå¤±: {epoch_loss:.4f}")
            print(f"     é‡å»ºæŸå¤±: {recon_loss:.4f}")
            print(f"     KLæŸå¤±: {kl_loss:.4f}")
            
            # ä¿å­˜æ ·æœ¬
            if (epoch + 1) % Config.save_interval == 0:
                self.save_samples(epoch)
            
            print("-" * 40)
        
        end_time = datetime.now()
        training_time = end_time - start_time
        
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"   æ€»è®­ç»ƒæ—¶é—´: {training_time}")
        print(f"   æœ€ç»ˆæŸå¤±: {self.train_losses[-1]:.4f}")
        
        return self.model
    
    def save_model(self, filepath="vae_model.pth"):
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            filepath: ä¿å­˜è·¯å¾„
        """
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'train_losses': self.train_losses,
            'recon_losses': self.recon_losses,
            'kl_losses': self.kl_losses,
            'config': {
                'latent_dim': Config.latent_dim,
                'learning_rate': Config.learning_rate,
                'batch_size': Config.batch_size,
                'epochs': Config.epochs
            }
        }, filepath)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filepath}")
    
    def load_model(self, filepath="vae_model.pth"):
        """
        åŠ è½½æ¨¡å‹
        
        Args:
            filepath: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        checkpoint = torch.load(filepath, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if 'train_losses' in checkpoint:
            self.train_losses = checkpoint['train_losses']
            self.recon_losses = checkpoint['recon_losses']
            self.kl_losses = checkpoint['kl_losses']
            
        print(f"ğŸ“‚ æ¨¡å‹å·²åŠ è½½: {filepath}")

def quick_train():
    """å¿«é€Ÿè®­ç»ƒå‡½æ•°"""
    try:
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = VAETrainer()
        
        # å¼€å§‹è®­ç»ƒ
        trained_model = trainer.train()
        
        # ä¿å­˜æ¨¡å‹
        trainer.save_model()
        
        return trained_model, trainer
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return None, None

if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œè®­ç»ƒ
    print("å¯åŠ¨VAEè®­ç»ƒ...")
    Config.print_config()
    
    trained_model, trainer = quick_train()
    
    if trained_model is not None:
        print("âœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    else:
        print("âŒ è®­ç»ƒå¤±è´¥ï¼")