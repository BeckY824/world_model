"""
VMCæ•°æ®é›†æ¨¡å— - ä½¿ç”¨MNISTè¿›è¡Œæ¼”ç¤º
"""
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
from config import VMCConfig

class VMCDataset:
    """VMCæ•°æ®é›†ç®¡ç†å™¨"""
    
    def __init__(self):
        self.config = VMCConfig()
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))  # MNISTæ ‡å‡†åŒ–
        ])
    
    def create_dataloaders(self):
        """åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®åŠ è½½å™¨"""
        # è®­ç»ƒæ•°æ®é›†
        train_dataset = datasets.MNIST(
            root='./data', 
            train=True,
            download=True, 
            transform=self.transform
        )
        
        # æµ‹è¯•æ•°æ®é›†
        test_dataset = datasets.MNIST(
            root='./data', 
            train=False,
            download=True, 
            transform=self.transform
        )
        
        # æ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_dataset, 
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=0,  # M1å…¼å®¹æ€§
            pin_memory=False
        )
        
        test_loader = DataLoader(
            test_dataset, 
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=False
        )
        
        print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ")
        print(f"   è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataset)}")
        print(f"   æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")
        print(f"   æ‰¹æ¬¡å¤§å°: {self.config.batch_size}")
        print(f"   è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"   æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")
        
        return train_loader, test_loader
    
    def visualize_samples(self, dataloader, save_path="results/data_samples.png"):
        """å¯è§†åŒ–æ•°æ®æ ·æœ¬"""
        import os
        
        # è·å–ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®
        data_iter = iter(dataloader)
        images, labels = next(data_iter)
        
        # é€‰æ‹©å‰16ä¸ªæ ·æœ¬è¿›è¡Œå¯è§†åŒ–
        sample_images = images[:16]
        sample_labels = labels[:16]
        
        # åˆ›å»º4x4çš„å­å›¾
        fig, axes = plt.subplots(4, 4, figsize=(8, 8))
        fig.suptitle('MNIST Dataset Samples', fontsize=16)
        
        for i, (ax, img, label) in enumerate(zip(axes.flat, sample_images, sample_labels)):
            # å°†å›¾åƒä»tensorè½¬æ¢å¹¶å»æ ‡å‡†åŒ–
            img_np = img.squeeze().numpy()
            img_np = img_np * 0.3081 + 0.1307  # åæ ‡å‡†åŒ–
            img_np = np.clip(img_np, 0, 1)
            
            ax.imshow(img_np, cmap='gray')
            ax.set_title(f'Label: {label.item()}')
            ax.axis('off')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š æ•°æ®æ ·æœ¬å¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    
    def get_sample_batch(self, dataloader):
        """è·å–ä¸€ä¸ªæ ·æœ¬æ‰¹æ¬¡ç”¨äºæµ‹è¯•"""
        data_iter = iter(dataloader)
        images, labels = next(data_iter)
        
        # å°†å›¾åƒå±•å¹³ä¸ºå‘é‡
        images_flat = images.view(images.size(0), -1)  # [batch_size, 784]
        
        return images_flat.to(self.config.device), labels.to(self.config.device)

def test_dataset():
    """æµ‹è¯•æ•°æ®é›†æ¨¡å—"""
    print("ğŸ§ª æµ‹è¯•VMCæ•°æ®é›†æ¨¡å—...")
    
    # åˆ›å»ºæ•°æ®é›†ç®¡ç†å™¨
    dataset_manager = VMCDataset()
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, test_loader = dataset_manager.create_dataloaders()
    
    # å¯è§†åŒ–æ ·æœ¬
    dataset_manager.visualize_samples(train_loader)
    
    # æµ‹è¯•è·å–æ ·æœ¬æ‰¹æ¬¡
    sample_images, sample_labels = dataset_manager.get_sample_batch(train_loader)
    print(f"æ ·æœ¬æ‰¹æ¬¡å½¢çŠ¶: å›¾åƒ {sample_images.shape}, æ ‡ç­¾ {sample_labels.shape}")
    
    print("âœ… æ•°æ®é›†æ¨¡å—æµ‹è¯•é€šè¿‡ï¼")

if __name__ == "__main__":
    test_dataset()