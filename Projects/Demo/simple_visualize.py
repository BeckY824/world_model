#!/usr/bin/env python3
"""
ç®€åŒ–çš„VMCå¯è§†åŒ–è„šæœ¬ - é¿å…segmentation faulté—®é¢˜
"""
import matplotlib
matplotlib.use('Agg')  # å¼ºåˆ¶ä½¿ç”¨éäº¤äº’å¼åç«¯

import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import os
from config import VMCConfig
from vmc_model import create_vmc_model
from dataset import VMCDataset

def simple_visualize_components():
    """ç®€åŒ–çš„VMCç»„ä»¶å¯è§†åŒ–"""
    
    print("ğŸ¨ ç®€åŒ–VMCå¯è§†åŒ–å¼€å§‹...")
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs('results', exist_ok=True)
    
    try:
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint_path = "checkpoints/vmc_checkpoint_epoch_3.pth"
        print(f"ğŸ“‚ åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=VMCConfig.device, weights_only=False)
        
        # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
        model = create_vmc_model(VMCConfig())
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        
        # åŠ è½½æ•°æ®
        dataset = VMCDataset()
        train_loader, test_loader = dataset.create_dataloaders()
        
        # è·å–ä¸€äº›æµ‹è¯•æ•°æ®
        with torch.no_grad():
            for images, labels in test_loader:
                images = images.to(VMCConfig.device)
                labels = labels.to(VMCConfig.device)
                
                # æ‰å¹³åŒ–å›¾åƒ [batch_size, 1, 28, 28] -> [batch_size, 784]
                images_flat = images.view(images.size(0), -1)
                
                # é€šè¿‡æ¨¡å‹è·å–å„ç»„ä»¶è¾“å‡º
                # Vç»„ä»¶ - å˜åˆ†ç¼–ç å™¨
                v_output, mu, logvar = model.variational_encoder(images_flat)
                
                # å°†å˜åˆ†ç¼–ç è½¬æ¢ä¸ºè®°å¿†æŸ¥è¯¢ (64 -> 32ç»´)
                memory_query = model.var_to_memory(v_output)
                
                # Mç»„ä»¶ - è®°å¿†æ¨¡å—  
                memory_output, attention_weights, mixture_probs = model.memory_module(memory_query)
                
                # Cç»„ä»¶ - æ§åˆ¶å™¨
                c_output, gate_weight = model.controller(v_output, memory_output)
                
                break  # åªå¤„ç†ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥ä¾¿å¯è§†åŒ–
        v_data = v_output.cpu().numpy()
        m_data = memory_output.cpu().numpy() 
        c_data = c_output.cpu().numpy()
        labels_np = labels.cpu().numpy()
        attention_data = attention_weights.cpu().numpy()
        mixture_data = mixture_probs.cpu().numpy()
        gate_data = gate_weight.cpu().numpy()
        
        print("ğŸ“Š å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # 1. Vç»„ä»¶å¯è§†åŒ– - ä½¿ç”¨PCAé™ç»´
        print("   ç”ŸæˆVç»„ä»¶å¯è§†åŒ–...")
        plt.figure(figsize=(12, 4))
        
        # Vç»„ä»¶çš„æ½œåœ¨ç©ºé—´åˆ†å¸ƒ
        plt.subplot(1, 3, 1)
        pca_v = PCA(n_components=2)
        v_2d = pca_v.fit_transform(v_data)
        scatter = plt.scatter(v_2d[:, 0], v_2d[:, 1], c=labels_np, cmap='tab10', alpha=0.7)
        plt.colorbar(scatter)
        plt.title('Vç»„ä»¶: å˜åˆ†æ½œåœ¨ç©ºé—´ (PCA)')
        plt.xlabel('PC1')
        plt.ylabel('PC2')
        
        # Vç»„ä»¶çš„å‡å€¼åˆ†å¸ƒ
        plt.subplot(1, 3, 2)
        mu_np = mu.cpu().numpy()
        plt.hist(mu_np.flatten(), bins=50, alpha=0.7, color='blue')
        plt.title('Vç»„ä»¶: æ½œåœ¨å‡å€¼åˆ†å¸ƒ')
        plt.xlabel('å€¼')
        plt.ylabel('é¢‘ç‡')
        
        # Vç»„ä»¶çš„æ–¹å·®åˆ†å¸ƒ
        plt.subplot(1, 3, 3)
        logvar_np = logvar.cpu().numpy()
        plt.hist(logvar_np.flatten(), bins=50, alpha=0.7, color='red')
        plt.title('Vç»„ä»¶: å¯¹æ•°æ–¹å·®åˆ†å¸ƒ')
        plt.xlabel('log(ÏƒÂ²)')
        plt.ylabel('é¢‘ç‡')
        
        plt.tight_layout()
        plt.savefig('results/v_component_visualization.png', dpi=150, bbox_inches='tight')
        plt.close()
        print("âœ… Vç»„ä»¶å¯è§†åŒ–å®Œæˆ: results/v_component_visualization.png")
        
        # 2. Mç»„ä»¶å¯è§†åŒ– - è®°å¿†æ¨¡å—
        print("   ç”ŸæˆMç»„ä»¶å¯è§†åŒ–...")
        plt.figure(figsize=(12, 4))
        
        # è®°å¿†è¾“å‡ºçš„PCA
        plt.subplot(1, 3, 1)
        pca_m = PCA(n_components=2)
        m_2d = pca_m.fit_transform(m_data)
        scatter = plt.scatter(m_2d[:, 0], m_2d[:, 1], c=labels_np, cmap='tab10', alpha=0.7)
        plt.colorbar(scatter)
        plt.title('Mç»„ä»¶: è®°å¿†è¾“å‡ºç©ºé—´ (PCA)')
        plt.xlabel('PC1')
        plt.ylabel('PC2')
        
        # è®°å¿†æ¨¡å—çš„é”®å€¼åˆ†å¸ƒ
        plt.subplot(1, 3, 2)
        memory_keys = model.memory_module.memory_keys.detach().cpu().numpy()
        plt.imshow(memory_keys, cmap='viridis', aspect='auto')
        plt.colorbar()
        plt.title('Mç»„ä»¶: è®°å¿†é”®çŸ©é˜µ')
        plt.xlabel('è®°å¿†ç»´åº¦')
        plt.ylabel('è®°å¿†æ§½')
        
        # è®°å¿†è¾“å‡ºåˆ†å¸ƒ
        plt.subplot(1, 3, 3)
        plt.hist(m_data.flatten(), bins=50, alpha=0.7, color='green')
        plt.title('Mç»„ä»¶: è®°å¿†è¾“å‡ºåˆ†å¸ƒ')
        plt.xlabel('å€¼')
        plt.ylabel('é¢‘ç‡')
        
        plt.tight_layout()
        plt.savefig('results/m_component_visualization.png', dpi=150, bbox_inches='tight')
        plt.close()
        print("âœ… Mç»„ä»¶å¯è§†åŒ–å®Œæˆ: results/m_component_visualization.png")
        
        # 3. Cç»„ä»¶å¯è§†åŒ– - æ§åˆ¶å™¨
        print("   ç”ŸæˆCç»„ä»¶å¯è§†åŒ–...")
        plt.figure(figsize=(12, 4))
        
        # æ§åˆ¶å™¨è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒ
        plt.subplot(1, 3, 1)
        c_probs = torch.softmax(torch.tensor(c_data), dim=1).numpy()
        for i in range(10):  # MNISTæœ‰10ä¸ªç±»
            class_probs = c_probs[labels_np == i].mean(axis=0)
            plt.bar(range(10), class_probs, alpha=0.7, label=f'çœŸå®ç±»{i}')
        plt.title('Cç»„ä»¶: å„ç±»åˆ«é¢„æµ‹æ¦‚ç‡')
        plt.xlabel('é¢„æµ‹ç±»åˆ«')
        plt.ylabel('å¹³å‡æ¦‚ç‡') 
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # é¢„æµ‹å‡†ç¡®æ€§
        plt.subplot(1, 3, 2)
        predictions = np.argmax(c_data, axis=1)
        accuracy_per_class = []
        for i in range(10):
            mask = labels_np == i
            if mask.sum() > 0:
                acc = (predictions[mask] == i).mean()
                accuracy_per_class.append(acc)
            else:
                accuracy_per_class.append(0)
        
        plt.bar(range(10), accuracy_per_class, color='orange', alpha=0.7)
        plt.title('Cç»„ä»¶: å„ç±»åˆ«å‡†ç¡®ç‡')
        plt.xlabel('ç±»åˆ«')
        plt.ylabel('å‡†ç¡®ç‡')
        plt.ylim(0, 1)
        
        # æ··æ·†çŸ©é˜µå¯è§†åŒ–
        plt.subplot(1, 3, 3)
        from sklearn.metrics import confusion_matrix
        cm = confusion_matrix(labels_np, predictions)
        plt.imshow(cm, cmap='Blues', interpolation='nearest')
        plt.colorbar()
        plt.title('Cç»„ä»¶: æ··æ·†çŸ©é˜µ')
        plt.xlabel('é¢„æµ‹ç±»åˆ«')
        plt.ylabel('çœŸå®ç±»åˆ«')
        
        plt.tight_layout()
        plt.savefig('results/c_component_visualization.png', dpi=150, bbox_inches='tight')
        plt.close()
        print("âœ… Cç»„ä»¶å¯è§†åŒ–å®Œæˆ: results/c_component_visualization.png")
        
        # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        print("   ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š...")
        overall_accuracy = (predictions == labels_np).mean()
        
        plt.figure(figsize=(10, 6))
        
        # æ€§èƒ½æŒ‡æ ‡
        plt.subplot(2, 2, 1)
        metrics = ['æ•´ä½“å‡†ç¡®ç‡', 'å¹³å‡ç±»åˆ«å‡†ç¡®ç‡', 'Vç»„ä»¶æ–¹å·®', 'Mç»„ä»¶æ¿€æ´»åº¦']
        values = [
            overall_accuracy,
            np.mean(accuracy_per_class),
            np.exp(logvar_np).mean(),  # å¹³å‡æ–¹å·®
            (m_data > 0).mean()  # è®°å¿†æ¿€æ´»æ¯”ä¾‹
        ]
        plt.bar(range(len(metrics)), values, color=['blue', 'green', 'red', 'orange'], alpha=0.7)
        plt.xticks(range(len(metrics)), metrics, rotation=45)
        plt.title('VMCæ•´ä½“æ€§èƒ½æŒ‡æ ‡')
        plt.ylabel('æ•°å€¼')
        
        # æŸå¤±ç»„æˆ
        plt.subplot(2, 2, 2)
        epoch_info = checkpoint.get('epoch_info', {})
        loss_components = ['åˆ†ç±»æŸå¤±', 'KLæŸå¤±', 'è®°å¿†æŸå¤±']
        loss_values = [
            epoch_info.get('classification_loss', 0),
            epoch_info.get('kl_loss', 0), 
            epoch_info.get('memory_loss', 0)
        ]
        plt.pie(loss_values, labels=loss_components, autopct='%1.1f%%', startangle=90)
        plt.title('æŸå¤±å‡½æ•°ç»„æˆ')
        
        # å„ç»„ä»¶ç»´åº¦åˆ†æ
        plt.subplot(2, 2, 3)
        component_dims = ['Vè¾“å‡º', 'Mè¾“å‡º', 'Cè¾“å‡º']
        dims = [v_data.shape[1], m_data.shape[1], c_data.shape[1]]
        plt.bar(component_dims, dims, color=['purple', 'cyan', 'yellow'], alpha=0.7)
        plt.title('å„ç»„ä»¶è¾“å‡ºç»´åº¦')
        plt.ylabel('ç»´åº¦æ•°')
        
        # è®­ç»ƒå†å²(å¦‚æœæœ‰)
        plt.subplot(2, 2, 4)
        if 'train_history' in checkpoint:
            history = checkpoint['train_history']
            epochs = range(1, len(history) + 1)
            plt.plot(epochs, [h['train_acc'] for h in history], 'b-', label='è®­ç»ƒå‡†ç¡®ç‡')
            plt.plot(epochs, [h['test_acc'] for h in history], 'r-', label='æµ‹è¯•å‡†ç¡®ç‡')
            plt.xlabel('Epoch')
            plt.ylabel('å‡†ç¡®ç‡')
            plt.legend()
            plt.title('è®­ç»ƒå†å²')
        else:
            plt.text(0.5, 0.5, 'è®­ç»ƒå†å²ä¸å¯ç”¨', ha='center', va='center', transform=plt.gca().transAxes)
            plt.title('è®­ç»ƒå†å²')
        
        plt.tight_layout()
        plt.savefig('results/vmc_comprehensive_report.png', dpi=150, bbox_inches='tight')
        plt.close()
        print("âœ… ç»¼åˆæŠ¥å‘Šå®Œæˆ: results/vmc_comprehensive_report.png")
        
        print("\nğŸ‰ VMCå¯è§†åŒ–å…¨éƒ¨å®Œæˆ!")
        print("ğŸ“Š ç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶:")
        print("   â€¢ results/v_component_visualization.png - Vç»„ä»¶(å˜åˆ†ç¼–ç å™¨)åˆ†æ")
        print("   â€¢ results/m_component_visualization.png - Mç»„ä»¶(è®°å¿†æ¨¡å—)åˆ†æ") 
        print("   â€¢ results/c_component_visualization.png - Cç»„ä»¶(æ§åˆ¶å™¨)åˆ†æ")
        print("   â€¢ results/vmc_comprehensive_report.png - VMCç»¼åˆæ€§èƒ½æŠ¥å‘Š")
        print(f"\nğŸ“ˆ æ•´ä½“æ€§èƒ½: å‡†ç¡®ç‡ {overall_accuracy:.2%}")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    simple_visualize_components()